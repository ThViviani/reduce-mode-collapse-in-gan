{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8-vdLn-fDG3"
   },
   "source": [
    "# Imports and inits consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:32:19.476743Z",
     "iopub.status.busy": "2025-06-05T12:32:19.476466Z",
     "iopub.status.idle": "2025-06-05T12:32:20.559655Z",
     "shell.execute_reply": "2025-06-05T12:32:20.558553Z",
     "shell.execute_reply.started": "2025-06-05T12:32:19.476722Z"
    },
    "id": "Qsl_kk7Er_0D",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove './reduce-mode-collapse-in-gan': No such file or directory\n",
      "Cloning into 'reduce-mode-collapse-in-gan'...\n",
      "remote: Enumerating objects: 291, done.\u001b[K\n",
      "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
      "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
      "remote: Total 291 (delta 21), reused 34 (delta 11), pack-reused 242 (from 1)\u001b[K\n",
      "Receiving objects: 100% (291/291), 5.38 MiB | 25.38 MiB/s, done.\n",
      "Resolving deltas: 100% (169/169), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -r ./reduce-mode-collapse-in-gan\n",
    "!git clone -b stacked_mnist_experiment https://github.com/ThViviani/reduce-mode-collapse-in-gan.git\n",
    "\n",
    "import sys; sys.path.append('./reduce-mode-collapse-in-gan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:32:20.561792Z",
     "iopub.status.busy": "2025-06-05T12:32:20.561478Z",
     "iopub.status.idle": "2025-06-05T12:35:14.795110Z",
     "shell.execute_reply": "2025-06-05T12:35:14.793949Z",
     "shell.execute_reply.started": "2025-06-05T12:32:20.561764Z"
    },
    "id": "Pd2_uZVusAX3",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightning==2.4.0 (from -r ./reduce-mode-collapse-in-gan/requirements.txt (line 1))\n",
      "  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting torch==2.4.0 (from -r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torch-fidelity==0.3.0 (from -r ./reduce-mode-collapse-in-gan/requirements.txt (line 3))\n",
      "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting torchvision==0.19.0 (from -r ./reduce-mode-collapse-in-gan/requirements.txt (line 4))\n",
      "  Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: wandb==0.19.9 in /usr/local/lib/python3.11/dist-packages (from -r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (0.19.9)\n",
      "Requirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (2025.3.2)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (0.14.3)\n",
      "Collecting packaging<25.0,>=20.0 (from lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1))\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (1.7.1)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (4.13.2)\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (2.5.1.post0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2)) (3.18.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2)) (1.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2)) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==3.0.0 (from torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2))\n",
      "  Downloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (11.1.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (1.15.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (4.3.8)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (3.20.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (7.0.0)\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (2.11.4)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (2.25.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (75.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2)) (12.9.41)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (3.11.18)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (2025.4.26)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning==2.4.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 1)) (1.20.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb==0.19.9->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 5)) (5.0.2)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch-fidelity==0.3.0->-r ./reduce-mode-collapse-in-gan/requirements.txt (line 3)) (2024.2.0)\n",
      "Downloading lightning-2.4.0-py3-none-any.whl (810 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.4.0-cp311-cp311-manylinux1_x86_64.whl (797.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
      "Downloading torchvision-0.19.0-cp311-cp311-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m994.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, packaging, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torch-fidelity, lightning\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.2.0\n",
      "    Uninstalling triton-3.2.0:\n",
      "      Successfully uninstalled triton-3.2.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
      "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.6.0+cu124\n",
      "    Uninstalling torch-2.6.0+cu124:\n",
      "      Successfully uninstalled torch-2.6.0+cu124\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.21.0+cu124\n",
      "    Uninstalling torchvision-0.21.0+cu124:\n",
      "      Successfully uninstalled torchvision-0.21.0+cu124\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.4.0 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed lightning-2.4.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 packaging-24.2 torch-2.4.0 torch-fidelity-0.3.0 torchvision-0.19.0 triton-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ./reduce-mode-collapse-in-gan/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:14.796886Z",
     "iopub.status.busy": "2025-06-05T12:35:14.796527Z",
     "iopub.status.idle": "2025-06-05T12:35:30.882381Z",
     "shell.execute_reply": "2025-06-05T12:35:30.881313Z",
     "shell.execute_reply.started": "2025-06-05T12:35:14.796829Z"
    },
    "id": "7YYQSfM5etH7",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torch_fidelity\n",
    "import wandb\n",
    "import gc\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from utils.utils import generate_some_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:30.885129Z",
     "iopub.status.busy": "2025-06-05T12:35:30.884457Z",
     "iopub.status.idle": "2025-06-05T12:35:30.896623Z",
     "shell.execute_reply": "2025-06-05T12:35:30.895611Z",
     "shell.execute_reply.started": "2025-06-05T12:35:30.885095Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Seed set to 999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "LATENT_SPACE_DIM = 128\n",
    "WANDB_TOKEN = '' # input your wandb token\n",
    "SEED = 999\n",
    "MAX_EPOCHS = 100\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:30.897996Z",
     "iopub.status.busy": "2025-06-05T12:35:30.897664Z",
     "iopub.status.idle": "2025-06-05T12:35:38.872068Z",
     "shell.execute_reply": "2025-06-05T12:35:38.871064Z",
     "shell.execute_reply.started": "2025-06-05T12:35:30.897966Z"
    },
    "id": "ZUqYWV2gy4fK",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdevelopsviviani\u001b[0m (\u001b[33mdevelopsviviani-clown-dev\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=WANDB_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b76_RRJ3fJb8"
   },
   "source": [
    "# Preparing StackedMnist dataset and loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:38.874123Z",
     "iopub.status.busy": "2025-06-05T12:35:38.873279Z",
     "iopub.status.idle": "2025-06-05T12:35:38.879800Z",
     "shell.execute_reply": "2025-06-05T12:35:38.878753Z",
     "shell.execute_reply.started": "2025-06-05T12:35:38.874085Z"
    },
    "id": "IV3RfxgNjqwR",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Pad(padding=2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5], [0.5]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:38.881251Z",
     "iopub.status.busy": "2025-06-05T12:35:38.880951Z",
     "iopub.status.idle": "2025-06-05T12:35:42.451752Z",
     "shell.execute_reply": "2025-06-05T12:35:42.450703Z",
     "shell.execute_reply.started": "2025-06-05T12:35:38.881221Z"
    },
    "id": "_i5JZtwXiUwg",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 56808284.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 1736339.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 14478842.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4384471.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw/train-images-idx3-ubyte/StackedMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from dataset_builders.stacked_mnist import StackedMNIST\n",
    "\n",
    "train_dataset = StackedMNIST(root='MNIST/raw/train-images-idx3-ubyte', train=True, download=True, transform=transform)\n",
    "val_dataset = StackedMNIST(root='MNIST/raw/train-images-idx3-ubyte', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:42.453335Z",
     "iopub.status.busy": "2025-06-05T12:35:42.453002Z",
     "iopub.status.idle": "2025-06-05T12:35:42.464232Z",
     "shell.execute_reply": "2025-06-05T12:35:42.463404Z",
     "shell.execute_reply.started": "2025-06-05T12:35:42.453302Z"
    },
    "id": "GDX1beKYkKzm",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "img, target = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:42.465608Z",
     "iopub.status.busy": "2025-06-05T12:35:42.465210Z",
     "iopub.status.idle": "2025-06-05T12:35:42.769706Z",
     "shell.execute_reply": "2025-06-05T12:35:42.768875Z",
     "shell.execute_reply.started": "2025-06-05T12:35:42.465577Z"
    },
    "id": "BcTZT0qcrMvw",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target:  tensor(364)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x79fce8ceae50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('target: ', train_dataset[0][1])\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:42.772711Z",
     "iopub.status.busy": "2025-06-05T12:35:42.772349Z",
     "iopub.status.idle": "2025-06-05T12:35:42.777742Z",
     "shell.execute_reply": "2025-06-05T12:35:42.776913Z",
     "shell.execute_reply.started": "2025-06-05T12:35:42.772690Z"
    },
    "id": "lzypa1USyTeB",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:42.779412Z",
     "iopub.status.busy": "2025-06-05T12:35:42.778787Z",
     "iopub.status.idle": "2025-06-05T12:35:43.195987Z",
     "shell.execute_reply": "2025-06-05T12:35:43.194721Z",
     "shell.execute_reply.started": "2025-06-05T12:35:42.779389Z"
    },
    "id": "TbcKKVh0zYA7",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 3, 32, 32])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5bzVOLd3BMg"
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:43.197735Z",
     "iopub.status.busy": "2025-06-05T12:35:43.197440Z",
     "iopub.status.idle": "2025-06-05T12:35:43.328241Z",
     "shell.execute_reply": "2025-06-05T12:35:43.327485Z",
     "shell.execute_reply.started": "2025-06-05T12:35:43.197704Z"
    },
    "id": "dP-Tvsqu4DOs",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 8, 4, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.discriminators import CriticStackedMNIST\n",
    "from models.generators import GeneratorStackedMNIST\n",
    "\n",
    "\n",
    "b = torch.randn(BATCH_SIZE, LATENT_SPACE_DIM)\n",
    "g = GeneratorStackedMNIST(z_dim=LATENT_SPACE_DIM)\n",
    "print(g(b).shape)\n",
    "\n",
    "\n",
    "d = CriticStackedMNIST(x_factor=4)\n",
    "d(torch.randn(256, 3, 32, 32), return_features=True)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:43.329444Z",
     "iopub.status.busy": "2025-06-05T12:35:43.329121Z",
     "iopub.status.idle": "2025-06-05T12:35:43.515829Z",
     "shell.execute_reply": "2025-06-05T12:35:43.514982Z",
     "shell.execute_reply.started": "2025-06-05T12:35:43.329406Z"
    },
    "id": "FW9hpLGVJ1ls",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 128])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.encoders import EncoderMNIST\n",
    "\n",
    "e = EncoderMNIST(x_shape=(3, 32, 32), z_dim=LATENT_SPACE_DIM, kernel_size=3, stride=2)\n",
    "\n",
    "e(torch.randn(256, 3, 32, 32)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:43.517195Z",
     "iopub.status.busy": "2025-06-05T12:35:43.516787Z",
     "iopub.status.idle": "2025-06-05T12:35:43.528908Z",
     "shell.execute_reply": "2025-06-05T12:35:43.528011Z",
     "shell.execute_reply.started": "2025-06-05T12:35:43.517175Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       " \n",
       "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          ...,\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "          [-1., -1., -1.,  ..., -1., -1., -1.]]]),\n",
       " tensor(364))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:43.530008Z",
     "iopub.status.busy": "2025-06-05T12:35:43.529760Z",
     "iopub.status.idle": "2025-06-05T12:35:43.546801Z",
     "shell.execute_reply": "2025-06-05T12:35:43.545887Z",
     "shell.execute_reply.started": "2025-06-05T12:35:43.529991Z"
    },
    "id": "THG2G0ZtL7Mv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from utils.train_options import TrainOptions\n",
    "\n",
    "train_options = TrainOptions(\n",
    "    latent_dim=LATENT_SPACE_DIM,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:43.548028Z",
     "iopub.status.busy": "2025-06-05T12:35:43.547736Z",
     "iopub.status.idle": "2025-06-05T12:35:43.590790Z",
     "shell.execute_reply": "2025-06-05T12:35:43.589912Z",
     "shell.execute_reply.started": "2025-06-05T12:35:43.548001Z"
    },
    "id": "75zuwLk3KQlr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from trainers.neighbors_embedding_gan import NEVanilaGAN, NERpGAN\n",
    "from trainers.dist_gan import DistVanilaGAN, DistRpGAN\n",
    "from trainers.standard_gan import StandardGAN\n",
    "from trainers.rp_gan import RpGAN\n",
    "from models.discriminators import CriticMNIST\n",
    "from datetime import datetime\n",
    "from trainers.dp_gan import DpVanilaGan, DpRpGAN\n",
    "from trainers.ne_gan_without_ae import NEVanilaGAN_hat, NERpGAN_hat\n",
    "\n",
    "\n",
    "def create_model_fn(model_class, use_encoder=False, use_r1r2=False):\n",
    "    def wrapper():\n",
    "        if model_class.__name__.find('Rp') != -1:\n",
    "            return model_class(\n",
    "                critic=CriticStackedMNIST(x_factor=2),\n",
    "                generator=GeneratorStackedMNIST(z_dim=LATENT_SPACE_DIM),\n",
    "                encoder=EncoderMNIST(x_shape=(3, 32, 32), z_dim=LATENT_SPACE_DIM, kernel_size=3, stride=2) if use_encoder else None,\n",
    "                use_r1r2_penalty=use_r1r2,\n",
    "                opt=train_options,\n",
    "            )\n",
    "        else:\n",
    "            return model_class(\n",
    "                critic=CriticStackedMNIST(x_factor=2),\n",
    "                generator=GeneratorStackedMNIST(z_dim=LATENT_SPACE_DIM),\n",
    "                encoder=EncoderMNIST(x_shape=(3, 32, 32), z_dim=LATENT_SPACE_DIM, kernel_size=3, stride=2) if use_encoder else None,\n",
    "                opt=train_options,\n",
    "            )\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "EXPERIMENTS = {\n",
    "    'DpVanilaGAN': create_model_fn(DpVanilaGan),\n",
    "    'NEVanilaGAN': create_model_fn(NEVanilaGAN, use_encoder=True),\n",
    "    'DistVanilaGAN': create_model_fn(DistVanilaGAN, use_encoder=True),\n",
    "    'NEVanilaGAN_hat': create_model_fn(NEVanilaGAN_hat),\n",
    "    'StandardGAN': create_model_fn(StandardGAN),\n",
    "    'RpGAN': create_model_fn(RpGAN),\n",
    "    'NERpGAN_hat': create_model_fn(NERpGAN_hat),\n",
    "    'DistRpGAN': create_model_fn(DistRpGAN, use_encoder=True),\n",
    "    'NERpGAN': create_model_fn(NERpGAN, use_encoder=True),\n",
    "    'DpRpGAN': create_model_fn(DpRpGAN),\n",
    "    'RpGAN_R1R2': create_model_fn(RpGAN, use_r1r2=True),\n",
    "    'NERpGAN_hat+R1R2': create_model_fn(NERpGAN_hat, use_r1r2=True),\n",
    "    'DistRpGAN+R1R2': create_model_fn(DistRpGAN, use_encoder=True, use_r1r2=True),\n",
    "    'NERpGAN+R1R2': create_model_fn(NERpGAN, use_encoder=True, use_r1r2=True),\n",
    "    'DpRpGAN+R1R2': create_model_fn(DpRpGAN, use_r1r2=True),\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(columns=[\n",
    "    'modes_covered',\n",
    "    'KL',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:43.592023Z",
     "iopub.status.busy": "2025-06-05T12:35:43.591726Z",
     "iopub.status.idle": "2025-06-05T12:35:43.597609Z",
     "shell.execute_reply": "2025-06-05T12:35:43.596801Z",
     "shell.execute_reply.started": "2025-06-05T12:35:43.591995Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def compute_kl_loss(true_labels, hat_labels, n_classes=1000):\n",
    "    counts = torch.bincount(true_labels.int(), minlength=n_classes)\n",
    "    p_real = (counts.float() / counts.sum())\n",
    "\n",
    "    counts = torch.bincount(hat_labels.int(), minlength=n_classes)\n",
    "    q = counts.float() / counts.sum()\n",
    "    q = torch.log(q + 1e-12)\n",
    "    \n",
    "    kl_loss = nn.KLDivLoss(reduction=\"sum\")\n",
    "    output = kl_loss(q, p_real)\n",
    "    return output.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:43.598775Z",
     "iopub.status.busy": "2025-06-05T12:35:43.598427Z",
     "iopub.status.idle": "2025-06-05T12:35:43.620410Z",
     "shell.execute_reply": "2025-06-05T12:35:43.619663Z",
     "shell.execute_reply.started": "2025-06-05T12:35:43.598747Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def forward_wrapper_for_stacked_mnist_classifier(classifier, loader, device, confidence=0.95):\n",
    "    results = []\n",
    "    for batch in tqdm(loader):\n",
    "        x, _ = batch\n",
    "        x = x.to(device)\n",
    "        classifier = classifier.to(device)\n",
    "        \n",
    "        labels = []\n",
    "        exist_uncofident_label = False\n",
    "        confidences = []\n",
    "        for channel in range(3):\n",
    "            digits_in_channel = x[:, channel, :, :].unsqueeze(dim=1)\n",
    "            logits = classifier(digits_in_channel)\n",
    "            p_logits = torch.nn.functional.softmax(logits).detach()\n",
    "            channel_confidences, labels_hat = torch.max(p_logits, dim=1)\n",
    "            labels.append(labels_hat)\n",
    "            confidences.append(channel_confidences)\n",
    "            \n",
    "        accepted_labels = (confidences[0] > confidence) * (confidences[1] > confidence) * (confidences[2] > confidence) # хотя бы одну цифру неуверено классифицирует == даем общий лейбл 000\n",
    "        result = 100 * labels[0] + 10 * labels[1] + labels[2]       \n",
    "        results.extend(result * accepted_labels)\n",
    "    return torch.Tensor(results)\n",
    "    \n",
    "\n",
    "def compute_modes_covered(preds_labels, n_classes=1000):\n",
    "    modes_covered = torch.bincount(preds_labels.int(), minlength=n_classes)\n",
    "    return (modes_covered > 0).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-05T12:35:43.622274Z",
     "iopub.status.busy": "2025-06-05T12:35:43.621621Z",
     "iopub.status.idle": "2025-06-05T12:35:43.646794Z",
     "shell.execute_reply": "2025-06-05T12:35:43.645811Z",
     "shell.execute_reply.started": "2025-06-05T12:35:43.622242Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "def get_loader_from_generated_images(images, batch_size=256):\n",
    "    dummy_labels = torch.zeros(images.shape[0])\n",
    "    generated_dataset = TensorDataset(images, dummy_labels)\n",
    "\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset=generated_dataset, batch_size=batch_size, shuffle=False, pin_memory=True\n",
    "    )\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from models.utils import ResNet50OnMNIST\n",
    "\n",
    "def compute_metrics(\n",
    "    trainer,\n",
    "    classifier=ResNet50OnMNIST(path_to_checkpoint='/kaggle/input/mnistclassifier/pytorch/default/1/resnet50_on_mnist_99.pth'), \n",
    "    n_samples=25600,\n",
    "    confidence=0.95,\n",
    "):\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    z = torch.randn(n_samples, LATENT_SPACE_DIM, device=trainer.device)\n",
    "    fake_images = trainer.generator(z)\n",
    "    generated_loader = get_loader_from_generated_images(fake_images) \n",
    "    preds_labels = forward_wrapper_for_stacked_mnist_classifier(classifier.to(device), generated_loader, device, confidence)\n",
    "    modes_covered = compute_modes_covered(preds_labels)\n",
    "    kl_loss = compute_kl_loss(train_dataset.targets, preds_labels)\n",
    "    return modes_covered, kl_loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-05T12:35:44.185165Z",
     "iopub.status.idle": "2025-06-05T12:35:44.185444Z",
     "shell.execute_reply": "2025-06-05T12:35:44.185328Z",
     "shell.execute_reply.started": "2025-06-05T12:35:44.185316Z"
    },
    "id": "MXpziChTK4At",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for name, model_fn in EXPERIMENTS.items():\n",
    "    print(f\"Running {name}\")\n",
    "\n",
    "    wandb_logger = WandbLogger(\n",
    "        project='StackedMNIST_vkr',\n",
    "        save_dir='',\n",
    "        log_model=True,\n",
    "        name=name + \"_\" + str(datetime.now())\n",
    "    )\n",
    "\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=MAX_EPOCHS,\n",
    "        logger=wandb_logger,\n",
    "        deterministic=True\n",
    "    )\n",
    "\n",
    "    model = model_fn()\n",
    "\n",
    "    trainer.fit(model=model, train_dataloaders=train_loader)\n",
    "\n",
    "    generate_some_examples(model.generator, BATCH_SIZE, LATENT_SPACE_DIM, model.device)\n",
    "    metrics = compute_metrics(model)\n",
    "    \n",
    "    print(metrics)\n",
    "    results.loc[name] = metrics\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    EXPERIMENTS[name] = model\n",
    "\n",
    "    # del model\n",
    "    del trainer\n",
    "    del wandb_logger\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-05T12:35:44.186358Z",
     "iopub.status.idle": "2025-06-05T12:35:44.186750Z",
     "shell.execute_reply": "2025-06-05T12:35:44.186556Z",
     "shell.execute_reply.started": "2025-06-05T12:35:44.186538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "isSourceIdPinned": true,
     "modelId": 364838,
     "modelInstanceId": 343560,
     "sourceId": 421590,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
